1. kafka数据接收和发送
    1. 总体概况：
        实时数据类型为key-data，flink官网提供的kafka-connector只支持value类型数据的读取和写入，需要自定义kafka-connector来读取和写入key-value类型的数据。
        value类型数据的读取和写入，依然使用官网提供的kafka-connector。
    3. 待解决问题：
        1. 目前自定义kafka-source只是单线程消费一个主题的所有分区数据，生产环境下主题分区数可能大于1，而且数据量很大，从优化角度考虑，后期需要通过多线程消费kafka不同分区数据。
            该问题已在2.1版本中解决。

2. 报警json数据处理
    将json报警数据中的模板编码、设备编码、测点编码使用 ~ 符号连接，作为map表的key值，value值设计为类对象，大类包含属性：
    测点名称、是否显隐、报警优先级、是否启用、值类型报警类集合、时长报警类集合
        1. 值类型报警类属性包含：最小值、最大值、报警编码、推送人员、角色、部门
        2. 时长类型报警类属性包含：时长（小时）、报警编码、推送人员、角色、推送领导、部门
    注意：
        由于值类型报警中的上限值或者下限值可能会不填写，因此在进行值类型报警判断时，必须一个一个进行比对，直到找到符合条件的为止。
        时长类型报警集合已经经过了排序，只需要找到前一个符合，后一个不符合，就可以确定时长报警符合前一个报警规则，无需再往后进行比对。

3. kafka连接器
    1. 1版本连接器使用一个线程消费两个主题的数据，性能较低。
    2. 2版本连接器对实时数据和规则数据主题进行多线程消费，一个线程固定消费一个分区数据。虽然对于flink的source来说，只能设置一个并行度，但是多线程消费可以增加处理能力。
        经过简单测试，一个线程发送数据很快，生产环境可以通过增加process并行度来增加flink处理能力。

4. A、B类型数据报警处理
    1. 区分规则
        A类型数据：一条json数据中，测点编码以 VA_ 开头（设备虚拟点）
        B类型数据：一条json数据中，测点编码以 VB_ 开头（灯）
    2. 报警处理
        由于kafka实时数据中A、B类型的数据值也都是数字，并且报警规则和C类型的数据报警规则完全一致，因此可以全部走C类型数据报警判断。
        最后发往kafka时，通过实时数据报警处理结果json中的测点编码来区分发往那个具体的kafka主题。

5. 优化
    1. 使用广播状态模式，将低频数据进行广播，优化数据传输。

6. 功能
    1. 增加异常捕获，组织异常信息并写入mysql，异常信息格式如下：
        时间、异常位置、具体错误信息、数据类型、错误值key、错误值value
            时间：
                yyyy-MM-dd HH:mm:ss
            异常位置：
                实时数据key值有误、实时数据value值有误、规则配置数据key值有误、规则配置数据value值有误
            数据类型：
                实时数据、规则配置数据

7. 故障/待机判断
    1. standbyFaultRule类用来保存故障/待机规则的具体信息。
    2. 使用map表保存所有规则：
        (1) key，String类型
            "FAULT" 用来保存故障判断规则（高优先级）
            "STANDBY" 用来保存待机判断规则
        (2) value，map类型
            (1) key，String类型，保存模板编码
            (2) value，List集合，保存对应模板下的所有判断规则
                List集合泛型为StandbyFaultRule。

8. 减少redis请求优化
    1. 在一条数据判断之前，直接取出对应设备整个报警记录（kafka一条实际数据就是一个设备的数据），处理完之后，再将新的数据写入到redis，相当于一条实时数据，只请求两次redis，而不是一个点就请求两次redis。