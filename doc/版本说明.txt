1. 1.0-SNAPSHOT
    1. 实现
        实现所有功能。
    2. 问题
        业务处理逻辑没有测试，而且规则数据的接收和实时数据的接收频率不一致，无法保持同步处理。

2. 2.0-SNAPSHOT
    1. 问题解决
        使用一个自定义kafka-source，同时消费两个主题的数据。消费完规则数据，将最新规则数据处理完之后保存到本地变量，消费完实时数据，则将实时数据和处理完的规则数据合并到一起发送给flink。
    2. 待实现
        目前只有一个线程去消费规则数据和实时数据的主题，生产环境实时数据主题数据量太大的情况下，需要单独开启多线程去消费实时数据主题，线程数和分区数保持一致。
        限制并行度为1，以保证规则数据永远是最新的。
        如果允许多并行度运行该source，则接收到新的规则数据时，必定只有一个线程获取到最新的规则数据，其他线程根本获取不到最新数据。
        虽然该问题可以使用全局变量来解决一个进程内的多线程数据共享问题，但是如果多个source线程分布在不同jobManager上，就无法解决了。
    3. 缺陷
        接收到实时数据时，可能没有接收到或者是没有处理完规则数据，因此刚启动时可能会丢失部分实时数据。

3. 2.1-SNAPSHOT
    1. 实现
        通过多线程消费，实现上一版本中的性能瓶颈问题。
    2. 功能
        该版本中除了实现了多线程解决性能瓶颈问题外，还保留了上个版本中单线程消费功能。
        如果实时数据主题只有一个分区，则直接使用2.0版本即可，不会造成数据的丢失。
    3. 缺陷
        由于阻塞队列的缓存设计，以及kafka的offset自动提交，任务的停止可能会造成实时数据的部分丢失。

4. 2.2-SNAPSHOT
    1. 功能升级
        该版本对2.1-SNAPSHOT中的2版本kafka连接器进行优化：
            2版本的kafka连接器增加一个配置参数，该参数课单独指定固定实时数据分区，以解决实时数据部分分区缺失造成程序异常的问题。

5. 2.3-SNAPSHOT
    1. 问题解决
        增加对字符串类型实时数据中value值的处理。
    2. 优化
        修改程序提交失败重启策略，修改为固定重启三次，每隔一分钟触发一次。

6. 2.4-SNAPSHOT
    1. bug修复
        值报警规则判断处理逻辑修改。
    本版本适合于处理C类型数据：实际点数据报警判断。

7. 2.5-SNAPSHOT
    1. 功能
        增加对B、C类型数据的报警判断处理。
        B：计算出来的灯
        C：计算出来的设备点

8. 2.6-SNAPSHOT
    1. 功能
        增加测点信息主题数据，通过测点信息数据查找测点的名称。

9. 3.0-SNAPSHOT
    1. 优化
        1. 使用flink-connector中的kafkaSource读取key-value类型的kafka数据。
        2. 使用广播状态模型处理低频次数据流，优化数据在算子之间的传输。
        3. 代码结构调整

10. 3.1-SNAPSHOT
    1. 优化
        1. 实时数据、规则数据、测点信息数据主题每次重启都是从最新offset开始读取，不用重新手动设置groupId来控制从最新位置开始消费。
        2. 取消配置文件中的groupId设置。

11. 3.2-SNAPSHOT
    1. 优化
        1. 去掉检查点机制，任然保留flink自动重启机制，间隔时间为10s，使得flink每次自动重启都是从最新位置开始消费数据，以解决错误数据造成程序异常的无限重启。
        2. 自动提交offset。
        3. 修改offset自动提交时长为10s。

12. 4.0-SNAPSHOT
    1. 功能
        增加异常捕获，将异常信息组织之后写入msyql

13. 4.1-SNAPSHOT
    1. 优化
        将测点名称处理和报警判断处理放到一个算子中，减少数据序列化/反序列化以及在算子之间的传输。

14. 5.0-SNAPSHOT
    1. 功能
        增加实时数据过滤功能，规则为：处理一段时间内的数据，然后丢弃一段时间内的数据，这两个时间段可以在配置文件中配置。

15. 5.1-SNAPSHOT
    1. 功能
        1. 去掉A、B类型数据报警时发送到报警主题中的数据，报警主题中只需要发送C类型数据的报警数据即可。
        2. 增加代码块执行时间统计功能（未完成）。
    2. bug修复
        1. mysql经常too many connections，还未解决。
        2. mysql数据入库之前未进行长度截断，容易造成数据过长无法入库问题。

15. 5.2-SNAPSHOT
    1. 功能
        1. 修改kafka主题中配置相关数据发送规则
            为方便后续增加数据处理规则，将原先报警判断规则数据发送kafka主题和测点名称合并到同一个主题，使用key作为不同类型规则配置相关数据的区分。
            新增加处理规则时，往同一个主题中发送数据即可，不用新增主题，以减少创建flink新source。
        2. 增加待机/故障判断
    2. 优化
        1. redis修改为集群

16. 5.3-SNAPSHOT
    1. 功能
        1. 增加重复数据过滤功能
        2. 在进行规则处理之前，对数据进行分组，通过kafka数据的key值进行区分，将同一设备的数据发送到下游同一个算子，避免redis高并发操作产生的重复报警数据。
    2. bug修复
        1. 重复报警
            fastJson将对象转化为json字符串，对象所属类的属性必须有对应的get/set方法，否则fastJson会忽略该属性。
        2. 值报警数据没有推送角色
            修改scala类，通过@BeanProperty注解生成get/set方法，避免手动编写get/set方法出错。

17. 5.4-SNAPSHOT
    1. 优化
        1. value值处理
            所有处理完的数据，其中的value数值按照字符串处理，直接将原始采集上来的数据中的value值写入即可。

18. 5.5-SNAPSHOT
    1. 功能
        1. 故障待机数据处理
            1. 去掉FAULT判断、修改为FAULTSTART/FAULTEND判断。
            2. 若一个设备的多个点触发判断，则发送多个点数据。

19. 5.6-SNAPSHOT
    1. 优化！
        1. Redis直接保存整个设备的数据，而不是保存单个测点的数据，以减少与Redis的交互。
        2. 去掉计算点数据与redis的交互。

20. 5.6.1-SNAPSHOT
    1. 优化！
        1. 设备报警和故障待机数据全部保存在算子内部，之后设备的数据被修改之后，将新的设备数据写入到redis中。
    2. 运行时长统计
        1. 统计算子内部代码运行和算子间数据传输时间。

21. 5.7-SNAPSHOT
    1. 功能
        1. 在实时数据处理算子增加累加器，以便于统计flink的吞吐量。